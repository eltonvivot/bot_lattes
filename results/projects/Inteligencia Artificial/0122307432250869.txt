2017 - Atual
ChurnLearn: Sistema Inteligente para Predição de Churn em Ambientes de Telefonia Móvel
Descrição: A invenção do sistema de telefonia é considerada uma das mais importantes realizações humanas, permitindo a comunicação e estreitamento dos laços entre as pessoas, independentemente de geografia e, consequentemente, alavancando, dentre outros benefícios, outras áreas de pesquisa. De maneira análoga, sistemas de telefonia móvel são a maior expressão desta relevância com mais de 7 bilhões de usuários em todo o mundo em 2014 de acordo com a International Telecommunication Union, agência das Nações Unidas especializada em telecomunicações. Disponibilizado universalmente em duas modalidades de cobrança (pós-pago e pré-pago), e tendo como base um modelo de negócios e de prestação de serviços fundamentalmente homogêneo em termos globais, o cancelamento de contratos em função da mudança de empresas prestadoras de serviço de telecomunicações, ocasionando o chamado \emph{churn}, é um aspecto relevante para todo o setor, especialmente no Brasil. De acordo com dados do próprio setor, no Brasil, dezenas de milhões de usuários acabam trocando de empresa prestadora de serviço de telecomunicações anualmente, gerando ineficiências econômicas importantes, e consequentemente amarras para o desenvolvimento socioeconômico do país. A presente proposta de projeto de pesquisa e inovação tecnológica visa o estudo da viabilidade da criação de um sistema computacional baseado em inteligência artificial que possa prever de maneira simples do ponto de vista das empresas, a partir do aprendizado do comportamento histórico dos usuários de empresas brasileiras que realizaram \emph{churn}, a propensão individual de \emph{churn} de usuários ativos com taxas de acerto que possibilitem sua utilização comercial. A aplicação prática deste projeto é possibilitar às empresas prestadoras de serviços de telecomunicações atuarem de maneira proativa junto aos usuários propensos a \emph{churn} com foco em reverter este processo, reduzindo, assim, os impactos financeiros negativos. Dada a relevância da modalidade pré-paga no mercado de telecomunicações brasileiro, e tendo o objetivo de provar a viabilidade da ideia, o foco desta pesquisa se restringe ao estudo de usuários desta modalidade neste mercado, porém com olhos atentos para a sua eventual aplicação a outras geografias, assim como também à modalidade pós-paga. Sem perda de generalidade, ainda não foram encontradas informações disponíveis sobre a existência de um sistema tecnológico com este escopo para o setor de telecomunicações brasileiro, que por sua vez se configura em um ambiente diferenciado do panorama global.. Situação: Em andamento; Natureza: Pesquisa. Alunos envolvidos: Graduação: (0)  / Especialização: (0)  / Mestrado acadêmico: (0)  / Mestrado profissional: (0)  / Doutorado: (0) . Integrantes: Danillo Roberto Pereira - Coordenador / Papa, João - Integrante.Financiador(es): Fundação de Amparo à Pesquisa do Estado de São Paulo - Auxílio
										financeiro.
2017 - Atual
Aplicação de Inteligência Artificial em Identificação de Padrões Ambientais
Descrição: Com o grande avanço dos problemas ambientais causados por interferência do ser humano na paisagem natural e ecossistemas, ferramentas que permitem realizar detecção e previsão de possíveis alterações pode ser de grande valia para criação de planos de contingência.
	A interferência do ser humano na natureza pode causar inconsistências ambientais como aumento de temperatura, excesso ou escassez de chuvas, modificações nas correntes de ar, temperatura desregulada em todo o planeta e epidemias que surgem sem um motivo aparente. Assim o presente projeto propõe a aplicação de métodos de aprendizado profundo para realização análise e estudo neste contexto.. Situação: Em andamento; Natureza: Pesquisa. Alunos envolvidos: Graduação: (1)  / Mestrado profissional: (1) . Integrantes: Danillo Roberto Pereira - Coordenador.
2014 - 2016
Aplicações em Computação Forense
Descrição: A Computação Forense é composta por um conjunto de técnicas e métodos de validação, identificação, interpretação, análise, documentação e apresentação de evidências científicas derivadas de meios digitais. O principal intuito da Computação Forense é reconstruir cenários e/ou contextos de modo a permitir que evidências sejam usadas criminalmente. A Computação Forense faz uso de um vasto ferramental computacional, utilizando método e algoritmo de diversas áreas da computação, como por exemplo: Processamento Digital de Imagens, Computação Gráfica, Visão Computacional e Inteligência Artificial.
Com o fácil acesso à internet, a facilidade e o baixo custo de aquisição de câmeras digitais, scanners e pacotes de software de edição de imagens; o número de manipulações e alteração de imagens e documentos digitais cresceu exponencialmente nos últimos anos. A maioria das manipulações e alterações são inocentes no que se refere a questões legais. Contudo, um aumento significativo de alterações criminosas tornou necessário o desenvolvimento de métodos e algoritmos eficazes para a detecção e identificação de manipulações. Principalmente quando um documento digital alterado está sendo usado como evidência em um júri. Além disso, indícios apontam que parte de imagens utilizadas em veículos científicos de renomada qualidade estão sendo adulteradas. Alguns autores também questionam a originalidade de algumas imagens de eventos históricos. Inserido neste contexto criou-se uma área específica denominada Análise Forense de Documentos Digitais.
Identificar a origem de documentos e/ou imagens digitais é uma temática atual e muito útil para diferentes aplicações. A identificação da fonte geradora (câmera) de uma imagem digital é comumente utilizada como indícios em casos de pedofilia. De modo geral os acusados se dizem usuários de pedofilia e não pedófilos, contudo se um perito conseguir ?provar? (com alto grau de confiabilidade) que as imagens em questão foram geradas por uma câmera que pertencem ao acusado, a chance de o mesmo ser condenado por pedofilia é maior. Já a identificação (com alto grau de confiabilidade) da fonte geradora (scanner) de uma cópia de um documento digital pode ser utilizada para identificar qual o scanner que permitiu o vazamento de um dado documento privado. Vale realçar que ambos dispositivos geralmente especificam as condições de aquisição em um cabeçalho (o EXIF no caso de imagens digitais), contudo, este pode ser facilmente alterado. 
Existem diversas metodologias que tratam estas problemáticas. De modo geral utilizam-se de características ?individuais? de cada dispositivo, como: defeitos de hardware (dead e hot pixels), anomalias na lente, correções no processo de geração da imagem, poeiras presentes na lente, entre outras. 
O presente projeto de pesquisa visa investigar e propor diferentes abordagens computacionais de modo a contribuir com soluções confiáveis para analisar a veracidade de documentos digitais e a identificação do dispositivo gerador de uma imagem ou documento digital.. Situação: Concluído; Natureza: Pesquisa. Integrantes: Danillo Roberto Pereira - Coordenador / SILVA, FRANCISCO ASSIS DA - Integrante / Leandro Luis Almeida - Integrante / Mario Augusto Pazoti - Integrante.
2014 - 2016
Aplicações e calibração de algoritmos de Fluxo Óptico
Descrição: Uma problemática comum no processamento de sequência de imagens (vídeos) é estimar o Fluxo Óptico, ou seja, o campo vetorial que representa a velocidade dos deslocamentos de uma sequência de imagens. O Fluxo Óptico é uma aproximação da projeção da velocidade tridimensional dos pontos de uma cena em uma imagem. De modo geral, o Fluxo Óptico de uma sequência imagens é obtido por meio de padrões de intensidade luminosa dos pixels. O Fluxo Óptico possui uma ampla gama de aplicações, como por exemplo: recuperação da velocidade de um dado objeto, rastreamento de objetos, entre outras aplicações (principalmente na área de Visão Computacional).  
Apesar de não se tratar de uma temática atual, o Fluxo Óptico tem sido foco de um vasto conjunto de pesquisas, haja vista que todas as metodologias propostas fazem uso de severas restrições e suposições. Novos métodos de Fluxo Óptico foram desenvolvidos nos últimos anos, levando a alguns avanços nesta área, bem como melhores resultados de correspondência entre os pixels de uma sequência de imagens. 
A maioria das abordagens que estimam o Fluxo Óptico exigem como entrada um conjunto de parâmetros que influenciam tanto na acurácia quanto no tempo de processamento. Deste modo, calibrar os algoritmos é uma tarefa de suma importância. Geralmente estes parâmetros são definidos empiricamente, sendo inviável para grandes bases de sequências de imagens. Além disso, um ajuste manual dos parâmetros requer um esforço humano considerável, sendo também mais propenso a erros. 
Na literatura referente ao Fluxo Óptico, a maioria dos trabalhos não consideram a seleção ideal de seu conjunto de parâmetros. De modo geral, os pesquisadores ajustam os parâmetros manualmente com o objetivo de minimizar alguma métrica ou taxa de erro. A tarefa de escolha de valores apropriados para métodos de Fluxo Óptico pode representar um grande problema combinatório que pode ser bem ajustada por algoritmos evolutivos, uma vez que tais técnicas de otimização evitam estagnação em mínimos locais. 
Inserido neste cenário, o presente projeto de pesquisa visa aplicar o Fluxo Óptico em diferentes contextos. 
Uma aplicação imediata é realizar a contagem e rastreamento de veículos em rodovias e estradas. Essa aplicação será usada para contagem de veículos em semáforos inteligentes.
Outra proposta do presente projeto é aplicar métodos evolutivos meta-heurísticos para a calibração dos algoritmos de Fluxo Óptico. Espera-se minimizar as métricas End Point Error (EPE) e Average Angular Error (AAE), e a percentagem de pixels com EPE superiores a 3. Tais métricas de avaliação quantitativa são comumente utilizadas pela comunidade de pesquisadores de Fluxo Óptico.. Situação: Concluído; Natureza: Pesquisa. Integrantes: Danillo Roberto Pereira - Coordenador / SILVA, FRANCISCO ASSIS DA - Integrante / Leandro Luis Almeida - Integrante / Mario Augusto Pazoti - Integrante.
2014 - Atual
Otimização de parâmetros e seleção de característica para métodos de Aprendizagem de Máquina
Descrição: Aprendizagem de máquina faz uso dos recursos da Inteligência Artificial, e utiliza métodos capazes de aprender automaticamente por meio de padrões extraídos de amostras. Estes métodos fazem uso de ferramental estatístico e possuem uma ampla gama de aplicações como, por exemplo: diagnóstico médico, detecção de fraudes em cartões de crédito, filtragem de spam em e-mails e análise de investimentos financeiros, dentre outras. 
Pode-se dividir os métodos de aprendizado de máquina em duas categorias básicas: aprendizado supervisionado e não-supervisionado. Nos métodos de aprendizado supervisionado utiliza-se um conjunto de exemplos pré-classificados (comumente referenciado como conjunto de treinamento) para treinar o método. Em algumas aplicações não é possível rotular as amostras do conjunto de treinamento, principalmente por ser uma tarefa muito onerosa. Neste caso é utilizado métodos de aprendizado não-supervisionado, ou seja, métodos que não requerem a pré-classificação das amostras do conjunto de treinamento, pois tais métodos têm como principal objetivo agrupar amostras menos discrepantes segundo alguma métrica de similaridade.
No caso de métodos que utilizam aprendizado supervisionado, uma vez executado o seu treinamento é necessário estimar uma medida de acurácia do mesmo. Para este fim, é comumente utilizado um conjunto de teste ou validação, cujas amostras são previamente rotuladas. Posteriormente, cada amostra deste conjunto é classificada pelo método em questão e o rótulo obtido é então comparado com o rótulo desejado. Se os rótulos forem iguais, considera-se que o mesmo obteve um acerto; caso contrário, considera que ocorreu um erro de classificação. Baseado neste critério, calcula-se o percentual de acertos do método, o qual será utilizado como uma métrica de acurácia. Pode-se também utilizar métricas de tempo de processamento de modo a comparar a eficiência dos métodos, principalmente quando a aplicação utilizada exige processamento em tempo real.
O desempenho e acurácia de alguns métodos de aprendizado de máquina são fortemente influenciados pela escolha de parâmetros internos dos algoritmos e pela seleção das características que serão utilizadas no processo de classificação. Desse modo, uma boa escolha destes parâmetros internos e uma seleção cuidadosa das características são cruciais para obtenção de bons resultados. Esta etapa é referenciada como ajuste de parâmetros internos ou otimização/seleção de parâmetros.
Além disso, os métodos de aprendizado de máquina trabalham com aplicações que utilizam um grande número de características para cada amostra, em muitos casos, devido à própria natureza do problema. Constam na literatura abordagens que empregam centenas de características para descrever as amostras do conjunto de dados, sendo que muitas destas são relativamente custosas de serem extraídas. Além disso, não existem garantias de que o aumento da dimensão do espaço de características propicie ganhos de acurácia.
Nesse contexto, o presente projeto de pesquisa objetiva o estudo e desenvolvimento de métodos para otimização de parâmetros em técnicas de aprendizado de máquina. Este projeto visa focar em algoritmos de otimização evolucionistas, dado que os mesmos têm sido amplamente utilizados em várias tarefas de otimização propiciando soluções elegantes e rápidas. Outro ponto importante deste projeto é que não são muitos os trabalhos na linha de pesquisa acima citada, sendo esta uma das principais contribuições deste projeto. Objetiva-se, ainda, aplicar um método de otimização não-linear desenvolvido pelo pesquisador Danillo Roberto Pereira (responsável), em seu doutorado, no contexto do presente projeto de pesquisa.
Vale ressaltar que algumas técnicas de otimização evolucionistas a serem empregadas neste trabalho foram desenvolvidas pelo Prof. Xin-She Yang (Cambridge/Inglaterra e Middlesex/Inglaterra), o qual tem co. Situação: Em andamento; Natureza: Pesquisa. Integrantes: Danillo Roberto Pereira - Coordenador / João Paulo Papa - Integrante.
2009 - 2013
Métodos de Aproximação para Computação Visual
Descrição: O objetivo deste projeto é o desenvolvimento de algoritmos, técnicas matemáticas e ferramentas de software para problemas de computação visual, baseadas em conceitos de aproximação matemática.
?Computação visual? é um nome conveniente para o conjunto de disciplinas que estudam a análise, processamento, geração e modelagem de imagens e vídeos digitais. Assim, este rótulo inclui geometria
computacional, modelagem geométrica, síntese de imagens e animações, visualização científica, visão computacional, codificação e processamento de imagens e reconhecimento de padrões. Computação
visual também é parte relevante de inúmeras disciplinas aplicadas, como informática médica, geoprocessamento, tecnologia aero-espacial, dados atmosféricos de tempo e clima, dados astrofísicos, dados relacionados ao clima espacial, exploração e preservação de recursos naturais, robótica e automação, planejamento urbano, projeto industrial, otimização, estatística, etc..
   Por aproximacão matemática entende-se a substituição de um fenômeno real ou modelo matemático complexo por um modelo mais simples ou mais eficiente, com garantias teóricas ou experimentais sobre
os erros decorrentes dessa substituição. O conceito é tão antigo quanto a própria matemática (haja visto, por exemplo, o trabalho de Arquimedes sobre a quadratura do círculo), é fundamental para toda a computação numérica. Sua importância decorre do fato familiar que muitas equações diferenciais e problemas geométricos, mesmo os mais simples, não possuem soluções que possam ser descritas por fórmulas fechadas.. Situação: Concluído; Natureza: Pesquisa. Integrantes: Danillo Roberto Pereira - Integrante / Anamaria Gomide - Integrante / Jorge Stolfi - Coordenador.Financiador(es): Fundação de Amparo à Pesquisa do Estado de São Paulo - Auxílio
										financeiro.