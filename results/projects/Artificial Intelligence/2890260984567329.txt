2022 - Atual
AVIATE: Exploração Sinergética de CNNs e Aceleradores em FPGA para Inferência Adaptativa na Borda
Descrição: Dispositivos da Internet das Coisas (IoT - Internet of Things), que são sistemas inteligentes com conexão à nuvem, estão em franca expansão e têm aplicações em diversas áreas. Entretanto, estes sistemas necessitam cada vez mais de respostas rápidas e com baixa latência e, por este motivo, o processamento computacional vem sendo progressivamente transferido da nuvem (cloud) para a borda (edge). Neste cenário, redes neurais cada vez mais profundas e, mais especificamente, convolucionais (CNN - Convolutional Neural Network), têm mostrado ser uma solução de alta acurácia para lidar com diversos problemas em IoT relacionados ao processamento de imagens, como lojas físicas inteligentes, carros autoguiados, reconhecimento facial para segurança, realidade aumentada e virtual, smarthomes e indústria 4.0. Para tratar do aumento significativo no volume de dados e complexidade computacional destas CNNs, e fazer com que elas trabalhem com baixa latência e alta vazão, este trabalho propõe o Framework AVIATE - Adaptive serVing of Inferences At The Edge, com o objetivo de aumentar a eficiência (i.e., vazão, energia, uso de recursos, acurácia ou custo de implementação) na execução de CNNs em aceleradores FPGAs na borda.. Situação: Em andamento; Natureza: Pesquisa. Integrantes: Arthur Francisco Lorenzon - Integrante / Antonio Carlos Schneider Beck - Coordenador / Mateus Rutzig Beck - Integrante.Financiador(es): Fundação de Amparo à Pesquisa do Estado do Rio Grande do Sul - Auxílio
										financeiro.
2021 - Atual
SkyNet: Towards Smart Data Planes
Situação: Em andamento; Natureza: Pesquisa. Alunos envolvidos: Graduação: (1)  / Mestrado acadêmico: (3)  / Mestrado profissional: (3) . Integrantes: Arthur Francisco Lorenzon - Coordenador / Marcelo Caggiani Luizelli - Integrante / Fábio Diniz Rossi - Integrante / MANSILHA, RODRIGO B. - Integrante / José Rodrigo Azambuja - Integrante / Luciano Pachoal Gaspary - Integrante / Leandro Aparecido Villas - Integrante / Ronaldo Alves Ferreira - Integrante / Weverton Luis da Costa Cordeiro - Integrante.Financiador(es): Fundação de Amparo à Pesquisa do Estado de São Paulo - Auxílio
										financeiro.
2020 - 2021
Transparent Optimization of Parallel Applications - HPC17LSSXE
Descrição: Thread-level parallelism (TLP) exploitation is being widely used to make the best use of hardware resources and improve performance. However, as the power consumption of high-performance computing systems is expected to significantly grow (up to 100 MW) in the next years, energy has become an important issue. Therefore, the objective when designing parallel applications is not to improve performance but to do so with a minimal impact on energy consumption.
However, neither performance nor energy improvements resulting from TLP exploitation are linear, and sometimes they do not scale as the number of threads increases. This means that in many cases, the maximum number of threads will not deliver the best results. One of the main issues of existing solutions that handle such a problem is that they usually involve transformation, which can be manual or automatic (by using specific languages or toolchains). These transformations modify the source or binary code or force the programmer to use an API that is not conventional or widespread used. However, as Intel and ARM have been showing with their families of ISAs (Instruction Set Architectures), binary compatibility is mandatory, so it is possible to reuse legacy code and to maintain traditional programming paradigms and libraries.
On top of that, several hardware-related reasons make this problem extremely complex: Instruction issue width saturation, off-chip bus saturation, data synchronization, concurrent shared memory accesses. Many of them will vary according to different aspects of the application and system at hand, which can only be defined at runtime, such as, Input set, metric evaluated, processor architecture, and number of parallel regions.
In addition to the complex scenario of choosing the ideal number of threads at runtime, several optimization techniques for power and energy consumption can be used, such as dynamic voltage and frequency scaling (DVFS) and power gating. The former is a feature of the processor that allows the application to adapt the clock frequency and operating voltage of the processor on the fly. It enables the software to change the processing performance to attain low power consumption while meeting the performance requirements. On the other hand, power gating consists of selectively powering down individual blocks in the chip while keeping other blocks powered up. In multi-core processors, it switches off unused cores to reduce power consumption. Therefore, in addition to selecting the ideal number of threads to execute an application, choosing the optimal processor frequency and turning off cores unused during the application execution may lead to a significant reduction in energy consumption with minimal impact on performance.
Considering the scenario discussed in the previous section, the main contribution of this work is to implement and evaluate a transparent and automatic approach for improving parallel applications regarding different metrics, such as the performance, energy, EDP, and the resource efficiency. The approach will be capable of adjusting the number of threads, the processor frequency (through DVFS), and the number of active cores (through power gating), without the need for any modifications in the source code or code recompilation. This work makes the following contributions:
- Develop a library to adjust the number of threads for OpenMP applications automatically. 
- Extend the library to adjust the number of threads of applications implemented with any parallel programming model.
- Develop an approach to adjust the processor frequency at runtime for parallel applications automatically. 
- Implement the power gating technique for parallel applications. Such implementation will have the goal to turn off the unused cores for saving energy with no impact on performance.. Situação: Concluído; Natureza: Pesquisa. Alunos envolvidos: Graduação: (0)  / Especialização: (0)  / Mestrado acadêmico: (0)  / Mestrado profissional: (0)  / Doutorado: (1) . Integrantes: Arthur Francisco Lorenzon - Coordenador / Antoni Munoz Navarro - Integrante / Vicenç Beltran Querol - Integrante.Financiador(es): European Commission H2020 - Research & Innovation - Auxílio
										financeiro.
2020 - Atual
Seamless Optimization of BLAS libraries through OmpSs-2 - HPC17DD65H
Descrição: New applications that involve the computation of common linear algebra operations have been pushing multithreaded processing to another level of performance requirements. However, at the same time that is necessary to increase performance, it is also mandatory to reduce the energy consumption since the power consumption of high-performance computing (HPC) systems is expected to significantly grow up in the next few years. Therefore, because most numerical applications running on HPC systems rely on linear algebra operations, optimizing the use of hardware resources is key to improve performance with minimal impact on the energy consumption.
On the path for improving the performance of common linear algebra operations (e.g., vector addition, scalar multiplication, linear combinations, and matrix multiplication), different libraries that implement the specifications defined by the Basic Linear Algebra Subprograms (BLAS) have been proposed. The BLAS-like Library Instantiation Software (BLIS) is one of them. It consists of a portable framework to rapidly instantiate high-performance libraries with BLAS functionality. However, several high-level frameworks used nowadays (e.g., Caffe, PyTorch, and TensorFlow) rely on standard BLAS libraries, such as the Intel Math Kernel Library (MKL). Even though they are capable of providing significant performance improvements when compared to the standard implementation of BLAS libraries, they cannot adapt the applications or the environment system at runtime. Such adaptability is key since many hardware and software aspects (e.g., off-chip bus saturation, data synchronization, and cache contention) may prevent linear improvements as one increases the number of cores executing the application. Therefore, providing a runtime system to automatically tune the application at runtime is essential to make a better use of the available hardware resources.
Given that, different programming models and runtime systems have been proposed to optimize the execution of parallel applications, such as OmpSs-2. It consists of a set of compiler directives and library functions that allows the software developer to exploit parallelism through the tasking model. OmpSs-2 is based on the Mercurium source-to-source compiler and the Nanos6 Runtime Library. While the Mercurium compiler provides the support for transforming high-level directives into a parallelized version of the application, the Nanos6 provides services to manage the parallelism (e.g., task creation, synchronization, data movement, and optimization of hardware resources).
Considering the aforementioned scenario, as far as we are concerned, all BLAS libraries relay on fork-join parallelization strategies to exploit multicore systems. Therefore, in this project, we plan to leverage the task-based data-flow execution model of OpenMP/OmpSs-2 to exploit multicore systems. In short, this collaboration project makes the following contributions:
Conduct a comprehensive study of the opportunities for optimizing the execution of BLIS framework.
Implement the routines from BLIS framework using the parallel tasking model provided by OmpSs-2. With that, high-level frameworks (e.g., Caffe, PyTorch, and TensorFlow) can benefit from the runtime optimizations provided by OmpSs-2 in a transparent way.
Extend the traditional BLIS interface to be able to chain BLAS operations; and
Modify the high-level frameworks to use the new interface provided by this work.. Situação: Em andamento; Natureza: Pesquisa. Alunos envolvidos: Graduação: (0)  / Especialização: (0)  / Mestrado acadêmico: (0)  / Mestrado profissional: (0)  / Doutorado: (0) . Integrantes: Arthur Francisco Lorenzon - Coordenador / Vicenç Beltran Querol - Integrante.Financiador(es): European Commission H2020 - Research & Innovation - Auxílio
										financeiro.
2019 - Atual
Execução Eficiente de Aplicações Paralelas de Maneira Automática e Transparente para o Usuário
Descrição: Projeto contemplado no edital: EDITAL FAPERGS 04/2019 - AUXÍLIO RECÉM DOUTOR-ARD
Com o aumento do número de transistores disponíveis para o projeto de processadores nos últimos anos, houve a popularização das arquiteturas com múltiplos núcleos para a execução de aplicações paralelas. Tais aplicações são encontradas em diferentes nichos: Aplicações de alto desempenho, que são executadas em servidores, afetam direta ou indiretamente a população, como cálculo da previsão do tempo e catástrofes ambientais, de busca por poços de petróleo, de sequenciamento de DNA e genomas, ou ainda na simulação de matemática financeira das grandes empresas. Em contrapartida, sistemas embarcados e computadores de mesa cada vez mais fazem uso da programação paralela em aplicativos e programas, envolvendo processamento de vídeo e áudio, jogos, e até mesmo navegadores de internet.
Estas aplicações vêm aumentando gradualmente em complexidade, requerendo um maior poder computacional. E, da mesma maneira, o consumo de energia se torna cada vez mais importante. De um lado, os processadores de propósito geral estão tendo seu aumento de desempenho limitado pela energia térmica do projeto, enquanto que a maioria dos sistemas embarcados são mantidos ligados através de uma bateria. Complementando esta restrição, o aumento da temperatura de operação dos componentes de hardware tem se tornado um desafio. A preocupação é respaldada por estudos que mostram que a vida útil do componente de hardware é reduzida pela metade quando ocorre o aumento de 10ºC em sua temperatura. Além disso, quanto maior a temperatura de operação, maior é o gasto com a refrigeração dos componentes. Desta forma, as aplicações não podem mais ser desenvolvidas apenas visando o desempenho. Pelo contrário, ele deve estar diretamente atrelado ao mínimo impacto no consumo de energia e na temperatura. Ao conseguir isto, o projetista estará reduzindo custos para manter o componente em operação (referente a energia) e custos relacionados a refrigeração dos componentes.. Situação: Em andamento; Natureza: Pesquisa. Alunos envolvidos: Graduação: (6)  / Mestrado acadêmico: (0)  / Mestrado profissional: (3)  / Doutorado: (1) . Integrantes: Arthur Francisco Lorenzon - Coordenador / ROSSI, F. D. - Integrante / Marcelo Caggiani Luizelli - Integrante / Alessandro Girardi - Integrante.Financiador(es): Fundação de Amparo à Pesquisa do Estado do Rio Grande do Sul - Outra.
2019 - Atual
Otimização do Uso de Recursos Computacionais através da Adaptação Dinâmica de Aplicações Paralelas
Descrição: Projeto contemplado no edital: EDITAL FAPERGS 05/2019 - PROGRAMA PESQUISADOR GAÚCHO-PQG
Com o aumento do número de transistores disponíveis para o projeto de processadores nos últimos anos, houve a popularização das arquiteturas com múltiplos núcleos para a execução de aplicações paralelas. Tais aplicações são encontradas em diferentes nichos: Aplicações de alto desempenho, que são executadas em servidores, afetam direta ou indiretamente a população, como cálculo da previsão do tempo e catástrofes ambientais, de busca por poços de petróleo, de sequenciamento de DNA e genomas, ou ainda na simulação de matemática financeira das grandes empresas. Em contrapartida, sistemas embarcados e computadores de mesa cada vez mais fazem uso da programação paralela em aplicativos e programas, envolvendo processamento de vídeo e áudio, jogos, e até mesmo navegadores de internet. Estas aplicações vêm aumentando gradualmente em complexidade, requerendo um maior poder computacional. E, da mesma maneira, o consumo de energia se torna cada vez mais importante. De um lado, os processadores de propósito geral estão tendo seu aumento de desempenho limitado pela energia térmica do projeto, enquanto a maioria dos sistemas embarcados são mantidos ligados através de uma bateria. Complementando esta restrição, o aumento da temperatura de operação dos componentes de hardware tem se tornado um desafio. A preocupação é respaldada por estudos que mostram que a vida útil do componente de hardware é reduzida pela metade quando ocorre o aumento de 10ºC em sua temperatura. Além disso, quanto maior a temperatura de operação, maior é o gasto com a refrigeração dos componentes. Desta forma, as aplicações não podem mais ser desenvolvidas apenas visando o desempenho. Pelo contrário, ele deve estar diretamente atrelado ao mínimo impacto no consumo de energia e na temperatura. Ao conseguir isto, o projetista estará reduzindo custos para manter o componente em operação (referente a energia) e custos relacionados a refrigeração dos componentes. Entretanto, a melhoria de desempenho resultante da paralelização de uma aplicação não é linear e, por vezes, não melhora proporcionalmente com o número de threads. Isto ocorre devido a vários fatores, e.g., sincronização e comunicação de dados, saturação da largura de banda disponível do barramento de comunicação e a concorrência por recursos internos do processador. O uso eficiente de recursos, desta maneira, é de extrema importância: Se uma aplicação executa com poucas threads, recursos de hardware podem ficar ociosos. Em contrapartida, esses mesmos recursos podem saturar devido ao alto número de threads que precisam ser executadas em paralelo. Em ambas as situações, a execução será ineficiente, o que pode resultar em lentidão ou consumo excessivo de energia e aumento da temperatura de operação. Assim, a abordagem natural dos projetistas de software paralelo que consideram a execução da aplicação com o maior número de threads possível em um sistema pode não ser a melhor solução. Considerando este cenário, escolher o número correto de threads a ser usado no desenvolvimento de aplicações paralelas pode fornecer melhorias significativas no desempenho, economia de energia e redução na temperatura dos componentes. Entretanto, este cenário é extremamente desafiador, por diversos motivos, como por exemplo, conjunto de entrada, métrica avaliada, número de núcleos e a quantidade de regiões paralelas de uma aplicação. Em adição a este complexo cenário de escolher o número ideal de threads em tempo de execução, diferentes técnicas de otimização do consumo de energia e potência podem ser usadas, como DVFS e power gating. DVFS é uma característica do processador que permite uma aplicação adaptar a frequência de clock e a tensão de operação do processador em tempo de execução Ele possibilita modificar o desempenho de.... Situação: Em andamento; Natureza: Pesquisa. Integrantes: Arthur Francisco Lorenzon - Coordenador / ROSSI, F. D. - Integrante / Marcelo Caggiani Luizelli - Integrante / Anderson Luiz Sartor - Integrante / Antonio Carlos Schneider Beck - Integrante.Financiador(es): Fundação de Amparo à Pesquisa do Estado do Rio Grande do Sul - Outra.
2019 - Atual
Telemetry Orchestration in Programmable Data Planes
Descrição: A telemetria in-band do plano de dados é um paradigma emergente de monitoramento em infraestruturas de rede. A partir da coleta distribuída e em tempo real de informações de monitoramento, é possível obter maior visibilidade do estado da infraestrutura e identificar um conjunto maior de problemas ? especialmente aqueles com curta duração (e.g., micro-burst). Estudos recentes na área têm concentrado esforços no desenvolvimento de mecanismos para (i) aumentar o nível de visibilidade das infraestruturas de rede e (ii) para o projeto de soluções de monitoramento. Entretanto, pouco ainda foi feito para coordenar o processo de coleta de informações de telemetria nesse novo paradigma. Isto é particularmente desafiador principalmente por dois motivos. Primeiro, dependendo de quais itens de telemetria da rede são coletados, a visibilidade da infraestrutura pode degradar em termos de consistência e atualização. Segundo, dependendo de como os itens de telemetria são coletados, o desempenho dos serviços de rede em operação e das aplicações de monitoramento podem ser prejudicados. Neste projeto, pretende-se investigar e modelar o problema de planejamento da coleta de itens de telemetria in-band. A ideia consiste em explorar o dinamismo entre os requisitos das aplicações de monitoramento e a aquisição dos itens de telemetria para, desta forma, garantir a acurácia do estado da infraestrutura e das aplicações de monitoramento. Posteriormente, pretendese, utilizando-se do conhecimento adquirido, operacionalizar as soluções obtidas em uma
infraestrutura real com suporte à programabilidade. Os resultados obtidos nesse projeto irão contribuir com os esforços de pesquisa relacionados a esse tema nos próximos anos.. Situação: Em andamento; Natureza: Pesquisa. Alunos envolvidos: Graduação: (1)  / Mestrado profissional: (3) . Integrantes: Arthur Francisco Lorenzon - Integrante / Marcelo Caggiani Luizelli - Coordenador / Fábio Diniz Rossi - Integrante / MANSILHA, RODRIGO B. - Integrante / Oscar Mauricio Caicedo Rendon - Integrante / Diego Luiz Kreutz - Integrante / Christian Esteve Rothenberg - Integrante / Fernando Manuel Valente Ramos - Integrante.Financiador(es): Fundação de Amparo à Pesquisa do Estado de São Paulo - Auxílio
										financeiro.
2018 - Atual
Uma Abordagem Automática, Dinâmica e Transparente para Otimizar o Desempenho e Consumo de Energia de Aplicações Paralelas em Sistemas de Propósito Geral e Embarcados
Descrição: A exploração eficiente do paralelismo no nível de threads em sistemas multicore tem sido um desafio para os desenvolvedores de software. Enquanto aumentar cegamente o número de threads pode melhorar o desempenho, isto também pode aumentar desproporcionalmente o consumo de energia. Por outro lado, técnicas de otimização utilizadas para reduzir o consumo de energia, tais como dynamic voltage and frequency scaling (DVFS) e power gating, podem levar a perda de desempenho se aplicadas incorretamente. Por esta razão, escolher corretamente o número de threads, o nível da frequência de operação do processador e o número de núcleos ativos é essencial para alcançar o melhor compromisso entre desempenho e energia. No entanto, esta tarefa é extremamente difícil: além do amplo número de variáveis envolvidas, muitas delas variam de acordo com diferentes aspectos do sistema e são definidas em tempo de execução, como por exemplo, o conjunto de entrada da aplicação, a métrica avaliada, a microarquitetura do processador, e o comportamento das regiões paralelas que compreendem a aplicação. Para abordar este complexo cenário, este projeto propõe a implementação de uma abordagem automática e transparente para melhorar aplicações paralelas implementadas com OpenMP considerando diferentes métricas: desempenho, energia e energy-delay product (EDP). Ele fará isso pelo ajuste do número de threads, a frequência do processador (através do DVFS), e o número de núcleos ativos (através do power gating), sem a necessidade de qualquer modificação no código fonte, recompilação de código ou interação do usuário final.. Situação: Em andamento; Natureza: Pesquisa. Alunos envolvidos: Doutorado: (5) . Integrantes: Arthur Francisco Lorenzon - Coordenador / ROSSI, F. D. - Integrante / Marcelo Caggiani Luizelli - Integrante / Antonio Carlos Schneider Beck - Integrante / Alessandro Girardi - Integrante.
2018 - Atual
METODO AUTOMATICO, TRANSPARENTE E DINAMICO PARA MELHORAR A EFICIENCIA ENERGETICA DE APLICACOES PARALELAS
Projeto certificado pelo(a) coordenador(a) Antonio Carlos Schneider Beck Filho em 10/05/2018.
Descrição: Com o aumento do número de transistores disponíveis para o projeto de processadores nos últimos anos, houve a popularização das arquiteturas com múltiplos núcleos (multicore) para a execução de aplicações paralelas. Tais aplicações são encontradas em diferentes nichos. Aplicações de HPC (High Performance Computing), que são executadas em servidores de alto desempenho, afetam direta ou indiretamente a população, como cálculo da previsão do tempo e catástrofes ambientais, de busca por poços de petróleo, de sequenciamento de DNA e genomas, ou ainda na simulação de matemática financeira das grandes empresas. Em contrapartida, sistemas embarcados (e.g.: tablets, smartphones, etc) cada vez mais fazem uso da programação paralela em apps, envolvendo, por exemplo, processamento de vídeo e áudio, jogos, e até mesmo navegadores de internet. 
Estas aplicações vêm aumentando gradualmente em complexidade, requerendo um maior poder computacional. E, da mesma maneira, o consumo de energia se torna cada vez mais importante. A previsão de potência consumida por sistemas de alto desempenho (HPC) em 2020 é de 200 MW (equivalente a uma usina nuclear de porte médio), de acordo com estudos do grupo de pesquisa em computação científica avançada do Departamento de Energia dos Estados Unidos. Os processadores de propósito geral (encontrados nos computadores de mesa) estão tendo seu aumento de desempenho limitado pela energia térmica do projeto (também chamado de TDP - Thermal Design Power). E, finalmente, a maioria dos sistemas embarcados são dispositivos móveis e mantidos ligados através de uma bateria. Portanto, o grande desafio tem sido não apenas aumentar o poder de processamento destes sistemas e o desempenho das aplicações paralelas, mas também fazer isso com o mínimo impacto no consumo de energia. 
Entretanto, a melhoria de desempenho resultante da paralelização de uma aplicação não é linear e, por vezes, não escala proporcionalmente com o número de threads. Isto ocorre devido a vários fatores, tais como: sincronização de dados, comunicação entre as threads, contenção, ou ainda largura de banda disponível do barramento de comunicação. Além do mais, a sincronização e comunicação tendem a aumentar o consumo de energia das aplicações paralelas, uma vez que a troca de dados ocorre através de regiões compartilhadas da memória. Estas regiões são hierarquicamente mais distantes do processador (por exemplo, memória cache L3 e compartilhada) e têm maior consumo de energia e tempo de acesso quando comparadas a memórias que estão mais próximas do processador (por exemplo, registradores e caches L1 e L2). Adicionalmente, instruções extras são executadas para este fim. Isto é, há um custo intrínseco quando um programa é paralelizado, tanto em termos de instruções quanto de dados. Este custo impacta tanto no desempenho quanto na energia consumida.
O uso eficiente de recursos, desta maneira, é de extrema importância. Se uma aplicação executa com poucas threads, recursos de hardware podem ficar ociosos (memórias, núcleos e barramento de comunicação). Em contrapartida, esses mesmos recursos podem saturar devido ao alto número de threads que precisam ser executadas em paralelo. Em ambas as situações, a execução será ineficiente, o que pode resultar em lentidão ou consumo excessivo de energia. Desta maneira, nem sempre executar o maior número de threads possível em um sistema pode ser a melhor solução, mesmo que este seja o pensamento comum. Considerando este cenário, escolher o número correto de threads a ser usado no desenvolvimento de aplicações paralelas pode fornecer melhorias significativas no desempenho e economia de energia.. Situação: Em andamento; Natureza: Pesquisa. Integrantes: Arthur Francisco Lorenzon - Integrante / Anderson Luiz Sartor - Integrante / Antonio Carlos Schneider Beck - Coordenador / Jeckson Delagostin Souza - Integrante.
2018 - Atual
SISTEMAS ADAPTATIVOS E TRANSPARENTES: OTIMIZANDO ALEM DE DESEMPENHO E ENERGIA
Projeto certificado pelo(a) coordenador(a) Antonio Carlos Schneider Beck Filho em 10/05/2018.
Descrição: Propõe-se um novo ambiente de projeto de processadores adaptativos, capaz de gerar sistemas que podem se adaptar, de forma automática (durante execução, sem intervenção alguma) e transparente (usando ferramentas e códigos compilados já existentes) à execução de programas com variados comportamentos e requerimentos, considerando o desempenho, a tolerância a falhas, consumo de energia e qualidade, no qual o peso (prioridade) de cada um pode ser definido a priori pelo projetista. Este ambiente de projeto será capaz de gerar sistemas adaptativos otimizados compostos de diferentes processadores e aceleradores, com o devido suporte de software, convergindo para uma arquitetura flexível com um espaço de projeto heterogêneo, oferecendo ao ao projetista diversas opções relativas às seguintes métricas: Qualidade; Tolerância a falhas; Transparência; Além das tradicionais: Desempenho; Energia; Área.. Situação: Em andamento; Natureza: Pesquisa. Integrantes: Arthur Francisco Lorenzon - Integrante / Antonio Carlos Schneider Beck - Coordenador / Jeckson Delagostin Souza - Integrante.
2016 - 2017
Energy Efficiency Evaluation of Parallel Programming Interfaces  in DataFlow Computers
Descrição: Thread-level parallelism (TLP) exploitation has been a challenge for software developers due to the energy restrictions in embedded and general-purpose processors: while it is necessary to take advantage of the availability of multiple cores to increase performance, it is also mandatory to consume less energy.
To speed up the development process and make it as transparent as possible, software designers use parallel programming interfaces (PPIs). However, the way how each PPI manages TLP exploitation (creation/finalization of thread/process, workload distribution, communication, and synchronization) highly influences performance, energy consumption, and energy-delay product (EDP), which varies across different processors. In previous works 12 , we demonstrated that it is possible to save up to 62% in energy consumption and achieve up to 88% of EDP improvements by just choosing the ideal PPI and degree of TLP.
Although an extensive evaluation has been performed in the aforementioned scenario, it was restricted to control flow processors. Currently, the dataflow paradigm has three important advantages when compared to control flow processors: speed, power, and size 3 . Despite these advantages, the parallel programming model for dataflow processors has its challenges to become an understood software development model. Therefore, the main goal of this cooperation project is to study and analyze different PPIs for data flow processors. The work to be developed will be divided into three stages:
   (i) Study the PPIs available for data flow processors. Is it possible to use the same PPIs used in the control flow processors? If so, how is this portability? Is the parallelism exploitation going to make it more difficult to develop software as it is today? What is the programming effort to implement a parallel application in this type of processor?
   (ii) Define and implement a representative set of programs to evaluate the behavior of each PPI in dataflow processors.
   (iii) Run the parallelized applications and analyze the results. If possible, compare them with the obtained results in the control flow processors. If the portability of the PPIs is possible, is the behavior similar in data flow and control flow processors?. Situação: Concluído; Natureza: Pesquisa. Alunos envolvidos: Doutorado: (1) . Integrantes: Arthur Francisco Lorenzon - Integrante / Antonio Carlos Schneider Beck - Integrante / Luigi Carro - Integrante / Roberto Giorgi - Coordenador.
2015 - Atual
Projeto Automático de MPSoCs Transparentes e Adaptáveis para Sistemas Embarcados
Projeto certificado pelo(a) coordenador(a) Antonio Carlos Schneider Beck Filho em 10/05/2018.
Descrição: Propõe-se um novo ambiente de projeto de processadores adaptativos, capaz de gerar sistemas que podem se adaptar, de forma automática (durante execução, sem intervenção alguma) e transparente (usando ferramentas e códigos compilados já existentes) à execução de programas com variados comportamentos e requerimentos, considerando o desempenho, a tolerância a falhas, consumo de energia e qualidade, no qual o peso (prioridade) de cada um pode ser definido a priori pelo projetista. Este ambiente de projeto será capaz de gerar sistemas adaptativos otimizados compostos de diferentes processadores e aceleradores, com o devido suporte de software, convergindo para uma arquitetura flexível com um espaço de projeto heterogêneo, oferecendo ao ao projetista diversas opções relativas às seguintes métricas: Qualidade; Tolerância a falhas; Transparência; Além das tradicionais: Desempenho; Energia; Área.. Situação: Em andamento; Natureza: Pesquisa. Integrantes: Arthur Francisco Lorenzon - Integrante / Antonio Carlos Schneider Beck - Coordenador / Jeckson Delagostin Souza - Integrante.
2014 - Atual
Programação Paralela Eficiente para Otimizar o Consumo de Energia em Sistemas Embarcados e de Propósito Geral
Descrição: Nos últimos anos, com o aumento do poder computacional dos sistemas embarcados, uma das maiores preocupações vem sendo o consumo de energia. A explicação para isto é porque a maioria destes sistemas (smartphones, tablets, etc) são mantidos ligados através de uma bateria. Portanto, o grande desafio tem sido não apenas aumentar o poder de processamento destes sistemas, mas também sua eficiência energética, isto é, maximizar o desempenho por joule consumido. 
Neste ímpeto de aumento de processamento, observa-se a popularização de sistemas embarcados que utilizam múltiplos núcleos (multicore), que visa o uso de múltiplos processadores para executar partes diferentes de um mesmo programa simultaneamente. Todavia, para que esta cooperação ocorra, os processadores deverão trocar informações em determinados momentos da execução. Em sistemas multicore, a troca de informações ocorre através do acesso simultâneo a regiões compartilhadas da memória. Entretanto, este acesso se dá em regiões da memória que estão hierarquicamente mais distantes do processador (memória cache L3 e principal), e que possuem consumo maior de energia, quando comparado ao acesso a memória privada de cada processador (memória cache L1 e L2). 
Desta maneira, enquanto a utilização de múltiplos núcleos visa o aumento de desempenho, o compartilhamento de informações entre estes núcleos, através da memória, leva a um consumo maior de energia: exatamente o que precisa ser evitado em sistemas embarcados móveis. Neste contexto, através da análise do consumo energético de Interfaces de Programação Paralela (IPP) largamente utilizadas (OpenMP, PThreads, Cilk++, entre outras) em diferentes arquiteturas e organizações (Intel Core i7, Intel Atom, ARM A9, ARM A15), esta proposta tem como intuito prover direções para o desenvolvedor para fazer o melhor uso possível do paralelismo de tarefas em sistemas embarcados visando o menor consumo de energia possível. Estas direções serão dadas através de fórmulas analíticas e ferramentas automatizadas de simulação.
Por consequência, nosso estudo, que está relacionado às áreas de processamento paralelo, arquitetura e organização de computadores e sistemas embarcados, fornecerá subsídios para determinar se o grau de paralelismo que oferece o melhor desempenho na paralelização de uma aplicação é também aquele que apresenta o consumo energético mais eficiente. Por exemplo, para uma determinada aplicação, pode-se optar por utilizar dois processadores, ao invés de quatro, caso a relação entre consumo de energia e eficiência seja mais favorável. O estudo também irá levar em consideração diferentes arquiteturas: a família Intel IA32, cujos processadores dominam os sistemas de computação pessoal e estão começando a ser utilizados também em sistemas embarcados; e a família ARM, que é a mais utilizada em dispositivos móveis, como smartphones e tablets, atualmente.. Situação: Em andamento; Natureza: Pesquisa. Alunos envolvidos: Graduação: (1)  / Mestrado acadêmico: (1)  / Doutorado: (1) . Integrantes: Arthur Francisco Lorenzon - Integrante / Anderson Luiz Sartor - Integrante / Antonio Carlos Schneider Beck - Coordenador / Márcia Cristina Cera - Integrante.
2013 - Atual
Análise do Impacto no Desempenho de Sistemas Embarcados pelo Uso da Programação Paralela
Descrição: Hoje em dia é cada vez mais comum vermos processadores multiprocessados, tanto em arquiteturas de uso comum como as multicore, quanto em dispositivos móveis. A programação paralela baseada em threads permite explorar o potencial computacional dos múltiplos núcleos de execução (cores) destas arquiteturas. Entretanto, enquanto a paralelização leva ao aumento do desempenho de um programa (redução do tempo de execução), o compartilhamento de informações entre núcleos via acessos à memória compartilhada, leva a um maior consumo de energia. Todavia, a preocupação com o consumo energético é uma constante para sistemas embarcados, tendo em vista que estes são alimentados por baterias. Adicionalmente, o acesso à memória além de gerar um alto consumo energético, também possui um forte impacto no desempenho das aplicações aplicações paralelas em função da disponibilidade dos dados. Neste sentido, este projeto busca estabelecer uma relação entre o consumo energético e o pico de desempenho de Interfaces de Programação Paralela (IPP) em ambientes de memória compartilhada. Serão estudadas as IPPs popularmente utilizadas tais como OpenMP, Pthreads, Cilk++, entre outras e diferentes arquiteturas tais como a família Intel IA32, cujos processadores dominam os sistemas de computação pessoal e estão começando a ser utilizados também em sistemas embarcados; e a família ARM, que é a mais utilizada em dispositivos móveis, como smartphones e tablets, atualmente. Com este estudo, espera-se elaborar um modelo analítico que seja capaz de orientar o desenvolvedor de como reduzir o impacto da exploração do paralelismo no consumo energético.. Situação: Em andamento; Natureza: Pesquisa. Alunos envolvidos: Mestrado acadêmico: (1) Doutorado: (2) . Integrantes: Arthur Francisco Lorenzon - Integrante / Antonio Carlos Schneider Beck - Coordenador / Márcia Cristina Cera - Integrante.
2012 - 2012
Estudo e desenvolvimento de Programas Paralelos: Como tirar proveito de Arquiteturas Paralelas
Descrição: Este projeto visa o estudo e desenvolvimento de Programas Paralelos como meio de explorar o paralelismo potencial das arquiteturas computacionais contemporâneas. Atualmente, no nosso dia a dia nos deparamos com uma série de arquiteturas paralelas como por exemplo computadores multicore ou placas de vídeo GP-GPUs. Entretanto, essas arquiteturas tendem a ser subutilizadas quando não existe o cuidado para aproveitar o potencial de processamento destas. Para aproveitar todo o poder computacional disponível é preciso fazer uso da programação paralela. Desenvolver programas paralelos não é uma tarefa trivial e exige conhecimento tanto das características da arquitetura quanto das funcionalidades disponibilizadas pelas ferramentas que viabilizam o desenvolvimento de programas paralelos. Este projeto tem por objetivo fomentar o estudo das técnicas de paralelização e a disseminação destes no meio acadêmico no Campus Alegrete. Com este projeto espera-se o desenvolvimento de programas paralelos, tanto referentes a aplicações científicas, como por exemplo para solucionar sistemas matemáticos que modelam fenômenos físicos e químicos, quanto aplicações que estimulem a interdisciplinariedade, como por exemplo para acelerar a execução de implementações de heurísticas e meta-heurísticas da área de inteligência artificial... Situação: Concluído; Natureza: Pesquisa. Alunos envolvidos: Graduação: (4) . Integrantes: Arthur Francisco Lorenzon - Integrante / Márcia Cristina Cera - Coordenador.Financiador(es): UNIPAMPA - EDITAL DE APOIO A GRUPOS DE PESQUISA 01/2012 - Bolsa / PROGRAMA DE BOLSAS DE INICIAÇÃO À PESQUISA - Bolsa.